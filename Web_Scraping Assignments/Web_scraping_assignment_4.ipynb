{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12ef1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's import all required libraries\n",
    "import selenium                                    #library that is used to work with selenium\n",
    "from selenium import webdriver                     # importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                                # to create dataframe\n",
    "from selenium.webdriver.common.by import By        # importing inbuilt class By\n",
    "import warnings                                    # to ignore any sort of warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import time                                        # use to stop search engine for few seconds\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b938683a",
   "metadata": {},
   "source": [
    "**1. Scrape the details of most viewed videos on YouTube from Wikipedia.**\n",
    "\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d95cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage  https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "url_1 = ' https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "\n",
    "driver.get(url_1)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c885f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list for scraping data\n",
    "Rank =[]\n",
    "Name =[]\n",
    "Artist =[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78126df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank Via X path\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting Name Via X path\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Name.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Name.append('NA')\n",
    "    \n",
    "# Extracting Artist Name Via Xpath\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Artist.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append('NA')\n",
    "\n",
    "# Extracting Upload date Via Xpath\n",
    "try:\n",
    "    upload_date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in upload_date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Upload_date.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append('NA') \n",
    "\n",
    "# Extracting Views via Xpath\n",
    "try:\n",
    "    views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Views.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Views.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5cb8863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30, 30, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rank),len(Name),len(Views),len(Upload_date),len(Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9de4fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMost Viewed Video on YouTube from Wikipedia :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views (in Billons)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>11.74</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.01</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.53</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[15]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.85</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.77</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.70</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>5.02</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.76</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[25]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.73</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.63</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.61</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.51</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.14</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.78</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.69</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.68</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.61</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.61</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.52</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.43</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.40</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[42]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.37</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[43]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.35</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.34</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.31</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.30</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.30</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.29</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.23</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Shake It Off\"[50]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.23</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Video Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                               \"Shape of You\"[15]   \n",
       "4    5.                                  \"Bath Song\"[17]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                                \"Uptown Funk\"[24]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[25]   \n",
       "9   10.                          \"Wheels on the Bus\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                       \"Roar\"[35]   \n",
       "15  16.                             \"Counting Stars\"[36]   \n",
       "16  17.                                     \"Axel F\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.                                 \"Dark Horse\"[41]   \n",
       "21  22.                                      \"Faded\"[42]   \n",
       "22  23.                             \"Girls Like You\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                               \"Shake It Off\"[50]   \n",
       "\n",
       "                                         Uploader Views (in Billons)  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories              11.74   \n",
       "1                                      Luis Fonsi               8.01   \n",
       "2                                     LooLoo Kids               6.53   \n",
       "3                                      Ed Sheeran               5.85   \n",
       "4                      Cocomelon – Nursery Rhymes               5.77   \n",
       "5                                     Wiz Khalifa               5.70   \n",
       "6                                       ChuChu TV               5.02   \n",
       "7                                     Mark Ronson               4.76   \n",
       "8                                     Miroshka TV               4.73   \n",
       "9                      Cocomelon – Nursery Rhymes               4.63   \n",
       "10                                            Psy               4.61   \n",
       "11                                     Get Movies               4.51   \n",
       "12                                      El Chombo               4.14   \n",
       "13                                       Maroon 5               3.78   \n",
       "14                                     Katy Perry               3.69   \n",
       "15                                    OneRepublic               3.68   \n",
       "16                                     Crazy Frog               3.61   \n",
       "17                                  Justin Bieber               3.61   \n",
       "18                                     Ed Sheeran               3.52   \n",
       "19                     Cocomelon – Nursery Rhymes               3.43   \n",
       "20                                     Katy Perry               3.40   \n",
       "21                                    Alan Walker               3.37   \n",
       "22                                       Maroon 5               3.35   \n",
       "23                                      Passenger               3.34   \n",
       "24                                        Shakira               3.31   \n",
       "25                                     Ed Sheeran               3.30   \n",
       "26                               Enrique Iglesias               3.30   \n",
       "27                                    Major Lazer               3.29   \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs               3.23   \n",
       "29                                   Taylor Swift               3.23   \n",
       "\n",
       "          Upload Date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3    January 30, 2017  \n",
       "4         May 2, 2018  \n",
       "5       April 6, 2015  \n",
       "6       March 6, 2014  \n",
       "7   November 19, 2014  \n",
       "8   February 27, 2018  \n",
       "9        May 24, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13   January 14, 2015  \n",
       "14  September 5, 2013  \n",
       "15       May 31, 2013  \n",
       "16      June 16, 2009  \n",
       "17   October 22, 2015  \n",
       "18    October 7, 2014  \n",
       "19      June 25, 2018  \n",
       "20  February 20, 2014  \n",
       "21   December 3, 2015  \n",
       "22       May 31, 2018  \n",
       "23      July 25, 2012  \n",
       "24       June 4, 2010  \n",
       "25   November 9, 2017  \n",
       "26     April 11, 2014  \n",
       "27     March 22, 2015  \n",
       "28   January 26, 2018  \n",
       "29    August 18, 2014  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for scrap data\n",
    "Wiki_YT=pd.DataFrame({'Rank':Rank,'Video Name':Name,'Uploader':Artist,'Views (in Billons)':Views,'Upload Date':Upload_date})\n",
    "print('\\033[1m'+'Most Viewed Video on YouTube from Wikipedia :'+'\\033[0m')\n",
    "Wiki_YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73b8e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c51baf",
   "metadata": {},
   "source": [
    "**2. Scrape the details team India’s international fixtures from bcci.tv.**\n",
    "\n",
    "\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "\n",
    "A) Match title (I.e. 1st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2e169a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage   https://www.bcci.tv/.\n",
    "\n",
    "url_2 = ' https://www.bcci.tv/.'\n",
    "\n",
    "driver.get(url_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "480c1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening fixtures webpage through browser\n",
    "\n",
    "fixtures=driver.find_element(By.XPATH,'//a[@class=\"nav-link \"]')\n",
    "try:\n",
    "    fixtures.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(fixtures.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "297f1885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping URL \n",
    "URL= []\n",
    "\n",
    "link=driver.find_elements(By.XPATH,'//a[@class=\"match-center-btn ng-scope\"]')\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1e754cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "27349833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f0db891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(URL):\n",
    "    driver.get(i)\n",
    "    \n",
    "    # Scraping Match title\n",
    "    try:\n",
    "        title=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/div[3]/div[7]/div[3]/div/div[1]/div/div[1]/div[2]')\n",
    "        Title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        Title.append('NA')\n",
    "        \n",
    "    # Scraping Series Via Xpath\n",
    "    try:\n",
    "        series=driver.find_element(By.XPATH,'//div[@class=\"tournament--name ng-binding ng-scope\"]')\n",
    "        Series.append(series.text)\n",
    "    except NoSuchElementException:\n",
    "        Series.append('NA')\n",
    "        \n",
    "    # Scraping venue Via Xpath\n",
    "    try:\n",
    "        place=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/div[3]/div[7]/div[3]/div/div[1]/div/div[2]/div[3]/div[3]/span[1]\")\n",
    "        Place.append(place.text)\n",
    "    except NoSuchElementException:\n",
    "        Place.append('NA')\n",
    "        \n",
    "    # Scraping date Via Xpath\n",
    "    try:\n",
    "        date=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/div[3]/div[7]/div[3]/div/div[1]/div/div[2]/div[3]/div[2]')\n",
    "        Date.append(date.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append('NA')     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7580a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Time Via Xpath\n",
    "time1=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div[1]/div[1]/div/div[1]/div/div[2]/h5/div')\n",
    "Time.append(time1.text)\n",
    "\n",
    "try:\n",
    "    time=driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "    for i in time:\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Time.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c1e80e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5f0810a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTeam India’s Upcoming International fixtures :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TARGET - 187\\nBANGLADESH NEED 70 RUN(S) TO WIN</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>SHERE BANGLA NATIONAL STADIUM, MIRPUR, DHAKA</td>\n",
       "      <td></td>\n",
       "      <td>LIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First-Class Match</td>\n",
       "      <td>INDIA A IN BANGLADESH MULTI DAY SERIES</td>\n",
       "      <td>SYLHET INTERNATIONAL CRICKET STADIUM</td>\n",
       "      <td>6 DEC 2022</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women's Youth T20 Match</td>\n",
       "      <td>NEW ZEALAND WM U19 IN INDIA T20 SERIES</td>\n",
       "      <td>SHARAD PAWAR CRICKET ACADEMY BKC</td>\n",
       "      <td>6 DEC 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>SHERE BANGLA NATIONAL STADIUM, MIRPUR</td>\n",
       "      <td>7 DEC 2022</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>DY PATIL STADIUM</td>\n",
       "      <td>9 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>ZAHUR AHMED CHOWDHURY STADIUM</td>\n",
       "      <td>10 DEC 2022</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>DY PATIL STADIUM</td>\n",
       "      <td>11 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>ZAHUR AHMED CHOWDHURY STADIUM</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Match Title  \\\n",
       "0  TARGET - 187\\nBANGLADESH NEED 70 RUN(S) TO WIN   \n",
       "1                               First-Class Match   \n",
       "2                         Women's Youth T20 Match   \n",
       "3                                         2nd ODI   \n",
       "4                                        1st T20I   \n",
       "5                                         3rd ODI   \n",
       "6                                        2nd T20I   \n",
       "7                                        1st Test   \n",
       "\n",
       "                                     Tournament  \\\n",
       "0   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23   \n",
       "1        INDIA A IN BANGLADESH MULTI DAY SERIES   \n",
       "2        NEW ZEALAND WM U19 IN INDIA T20 SERIES   \n",
       "3   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23   \n",
       "4            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "5   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23   \n",
       "6            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "7  INDIA TOUR OF BANGLADESH TEST SERIES 2022-23   \n",
       "\n",
       "                                          Venue         Date          Time  \n",
       "0  SHERE BANGLA NATIONAL STADIUM, MIRPUR, DHAKA                       LIVE  \n",
       "1          SYLHET INTERNATIONAL CRICKET STADIUM   6 DEC 2022   9:00 AM IST  \n",
       "2              SHARAD PAWAR CRICKET ACADEMY BKC   6 DEC 2022   1:00 PM IST  \n",
       "3         SHERE BANGLA NATIONAL STADIUM, MIRPUR   7 DEC 2022  11:30 AM IST  \n",
       "4                              DY PATIL STADIUM   9 DEC 2022   7:00 PM IST  \n",
       "5                 ZAHUR AHMED CHOWDHURY STADIUM  10 DEC 2022  11:30 AM IST  \n",
       "6                              DY PATIL STADIUM  11 DEC 2022   7:00 PM IST  \n",
       "7                 ZAHUR AHMED CHOWDHURY STADIUM  14 DEC 2022   9:30 AM IST  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for scrap data\n",
    "Cricket=pd.DataFrame({'Match Title':Title,'Tournament':Series,'Venue':Place,'Date':Date,'Time':Time})\n",
    "print('\\033[1m'+'Team India’s Upcoming International fixtures :'+'\\033[0m')\n",
    "Cricket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fe685e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc290ea",
   "metadata": {},
   "source": [
    "**3. Scrape the details of selenium exception from guru99.com.**\n",
    "\n",
    "Url = https://www.guru99.com/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Description\n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4cab36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage   https://www.guru99.com/\n",
    "\n",
    "url_3 = 'https://www.guru99.com/'\n",
    "\n",
    "driver.get(url_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b37ec267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Selenium option from website\n",
    "try:\n",
    "    Selenium=driver.find_element(By.XPATH,'//*[@id=\"kt-info-box_eaeb48-11\"]/a/div[2]/h5')\n",
    "    Selenium.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(Selenium.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c4a799fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Selenium Exception handling option from website\n",
    "Selenium_Exception=driver.find_element(By.XPATH,'//*[@id=\"post-193\"]/div/div/table[5]/tbody/tr[34]/td[1]/a')\n",
    "try:\n",
    "    Selenium_Exception.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(Selenium_Exception.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "63046113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list\n",
    "Name =[]\n",
    "Description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4e2025fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=driver.find_elements(By.XPATH,'//*[@id=\"post-1953\"]/div/div/p[1]/strong')\n",
    "for i in n:\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2957ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Exception Name via Xpath\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//table[@class=\"table table-striped\"]/tbody/tr/td[1]')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')\n",
    "    \n",
    "# Extracting Description via Xpath\n",
    "try:\n",
    "    description=driver.find_element(By.XPATH,'//table[@class=\"table table-striped\"]/tbody/tr/td[2]')\n",
    "    Description.append(description.text)\n",
    "except NoSuchElementException:\n",
    "    Description.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f499d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[1]')\n",
    "Name.append(name.text.split(':')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a4c19",
   "metadata": {},
   "source": [
    "**4. Scrape the details of State-wise GDP of India from statisticstime.com.**\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(18-19)- at current prices\n",
    "\n",
    "D) GSDP(19-20)- at current prices\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13d24d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage http://statisticstimes.com/\n",
    "\n",
    "url_4 = 'http://statisticstimes.com/'\n",
    "\n",
    "driver.get(url_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97189e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty lists\n",
    "Rank =[]\n",
    "State =[]\n",
    "GDSP_18_19 =[]\n",
    "GDSP_19_20=[]\n",
    "Share =[]\n",
    "GDP =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8360a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on India under ecomony section\n",
    "India=driver.find_element(By.XPATH,'//div[@class=\"dropdown\"][2]/div/a[3]')\n",
    "try:\n",
    "    India.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(India.get_attribute('href'))\n",
    "    \n",
    "time.sleep(2)\n",
    "\n",
    "# Clicking Indian State GDP\n",
    "state = driver.find_element(By.XPATH,'//ul[@style=\"list-style-type:none;margin-left:20px;\"]/li[1]/a')\n",
    "try:\n",
    "    state.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(state.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21286217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank via Xpath\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting state name via Xpath\n",
    "try:\n",
    "    state=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in state:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append('NA')\n",
    "    \n",
    "# Extracting GDSP 19-20 via Xpath\n",
    "try:\n",
    "    gdsp_19_20=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gdsp_19_20:\n",
    "        GDSP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_19_20.append('NA')\n",
    "    \n",
    "# Extracting GDSP 18-19 via Xpath\n",
    "try:\n",
    "    gdsp_18_19=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gdsp_18_19:\n",
    "        GDSP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_18_19.append('NA')\n",
    "    \n",
    "# Extracting share in billons via Xpath\n",
    "try:\n",
    "    share=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share:\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append('NA')\n",
    "\n",
    "# Extracting GDP via Xpath\n",
    "try:\n",
    "    gdp=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16726fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mState-wise GDP of India :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GDSP 19-20</th>\n",
       "      <th>GDSP 18-19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GDSP 19-20 GDSP 18-19   Share  \\\n",
       "0     1                Maharashtra          -  2,632,792  13.94%   \n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208   8.63%   \n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764   8.39%   \n",
       "3     4                    Gujarat          -  1,502,899   7.96%   \n",
       "4     5                  Karnataka  1,631,977  1,493,127   7.91%   \n",
       "5     6                West Bengal  1,253,832  1,089,898   5.77%   \n",
       "6     7                  Rajasthan  1,020,989    942,586   4.99%   \n",
       "7     8             Andhra Pradesh    972,782    862,957   4.57%   \n",
       "8     9                  Telangana    969,604    861,031   4.56%   \n",
       "9    10             Madhya Pradesh    906,672    809,592   4.29%   \n",
       "10   11                     Kerala          -    781,653   4.14%   \n",
       "11   12                      Delhi    856,112    774,870   4.10%   \n",
       "12   13                    Haryana    831,610    734,163   3.89%   \n",
       "13   14                      Bihar    611,804    530,363   2.81%   \n",
       "14   15                     Punjab    574,760    526,376   2.79%   \n",
       "15   16                     Odisha    521,275    487,805   2.58%   \n",
       "16   17                      Assam          -    315,881   1.67%   \n",
       "17   18               Chhattisgarh    329,180    304,063   1.61%   \n",
       "18   19                  Jharkhand    328,598    297,204   1.57%   \n",
       "19   20                Uttarakhand          -    245,895   1.30%   \n",
       "20   21            Jammu & Kashmir          -    155,956   0.83%   \n",
       "21   22           Himachal Pradesh    165,472    153,845   0.81%   \n",
       "22   23                        Goa     80,449     73,170   0.39%   \n",
       "23   24                    Tripura     55,984     49,845   0.26%   \n",
       "24   25                 Chandigarh          -     42,114   0.22%   \n",
       "25   26                 Puducherry     38,253     34,433   0.18%   \n",
       "26   27                  Meghalaya     36,572     33,481   0.18%   \n",
       "27   28                     Sikkim     32,496     28,723   0.15%   \n",
       "28   29                    Manipur     31,790     27,870   0.15%   \n",
       "29   30                   Nagaland          -     27,283   0.14%   \n",
       "30   31          Arunachal Pradesh          -     24,603   0.13%   \n",
       "31   32                    Mizoram     26,503     22,287   0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -       -   \n",
       "\n",
       "   GDP (in Billions)  \n",
       "0            399.921  \n",
       "1            247.629  \n",
       "2            240.726  \n",
       "3            228.290  \n",
       "4            226.806  \n",
       "5            165.556  \n",
       "6            143.179  \n",
       "7            131.083  \n",
       "8            130.791  \n",
       "9            122.977  \n",
       "10           118.733  \n",
       "11           117.703  \n",
       "12           111.519  \n",
       "13            80.562  \n",
       "14            79.957  \n",
       "15            74.098  \n",
       "16            47.982  \n",
       "17            46.187  \n",
       "18            45.145  \n",
       "19            37.351  \n",
       "20            23.690  \n",
       "21            23.369  \n",
       "22            11.115  \n",
       "23             7.571  \n",
       "24             6.397  \n",
       "25             5.230  \n",
       "26             5.086  \n",
       "27             4.363  \n",
       "28             4.233  \n",
       "29             4.144  \n",
       "30             3.737  \n",
       "31             3.385  \n",
       "32                 -  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for scrap data\n",
    "Statewise_GDP=pd.DataFrame({'Rank':Rank,'State':State,'GDSP 19-20':GDSP_19_20,'GDSP 18-19':GDSP_18_19,\n",
    "                            'Share':Share,'GDP (in Billions)':GDP})\n",
    "print('\\033[1m'+'State-wise GDP of India :'+'\\033[0m')\n",
    "Statewise_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3773c5",
   "metadata": {},
   "source": [
    "**5. Scrape the details of trending repositories on Github.com.**\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd279dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage https://github.com/\n",
    "\n",
    "url_5 = 'https://github.com/'\n",
    "\n",
    "driver.get(url_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80b393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on trending option\n",
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a')\n",
    "try:\n",
    "    trending.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33cb9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list for Scraping Data\n",
    "Title=[]\n",
    "Description=[]\n",
    "Count =[]\n",
    "Language =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c30521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping repositories URL\n",
    "URL= []\n",
    "link=driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d71b1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab315f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Repositority Title\n",
    "try:\n",
    "    title=driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]')\n",
    "    for i in title:\n",
    "        Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Title.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22947585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de2694c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [07:24<00:00, 17.79s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(URL):\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    # Scraping Description\n",
    "    try:\n",
    "        description=driver.find_element(By.XPATH,'/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[1]/div/p')\n",
    "        Description.append(description.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('NA')\n",
    "    \n",
    "    # Scraping Contributor count\n",
    "    try:\n",
    "        count=driver.find_element(By.XPATH,\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        Count.append(count.text)\n",
    "    except NoSuchElementException:\n",
    "        Count.append('NA')\n",
    "    \n",
    "    # Scraping Language\n",
    "    L =[]\n",
    "    try:\n",
    "        lang=driver.find_elements(By.XPATH,\"//li[@class='d-inline']//a//span[1]\")\n",
    "        if lang:\n",
    "            for j in lang:\n",
    "                L.append(j.text)\n",
    "        else:\n",
    "            L.append('NA')\n",
    "        Language.append(L)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "736dd20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mGitHub Trending Repository :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invoke-ai / InvokeAI</td>\n",
       "      <td>NA</td>\n",
       "      <td>130</td>\n",
       "      <td>[Jupyter Notebook, Python, TypeScript, SCSS, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple / ml-stable-diffusion</td>\n",
       "      <td>NA</td>\n",
       "      <td>2</td>\n",
       "      <td>[Python, Swift]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AleoHQ / snarkOS</td>\n",
       "      <td>NA</td>\n",
       "      <td>45</td>\n",
       "      <td>[Rust, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>misskey-dev / misskey</td>\n",
       "      <td>NA</td>\n",
       "      <td>121</td>\n",
       "      <td>[TypeScript, Vue, JavaScript, Pug, SCSS, CSS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Klipper3d / klipper</td>\n",
       "      <td>NA</td>\n",
       "      <td>327</td>\n",
       "      <td>[C, Python, C++, Assembly, Makefile, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PKUFlyingPig / cs-self-learning</td>\n",
       "      <td>NA</td>\n",
       "      <td>70</td>\n",
       "      <td>[HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>danielgross / whatsapp-gpt</td>\n",
       "      <td>NA</td>\n",
       "      <td>2</td>\n",
       "      <td>[Go, Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hehonghui / awesome-english-ebooks</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>[CSS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visualize-ML / Book4_Power-of-Matrix</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thangchung / go-coffeeshop</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>[Go, HTML, HCL, JavaScript, CSS, Shell, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>monicahq / monica</td>\n",
       "      <td>NA</td>\n",
       "      <td>251</td>\n",
       "      <td>[PHP, Vue, Blade, Shell, Dockerfile, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>coolsnowwolf / lede</td>\n",
       "      <td>NA</td>\n",
       "      <td>355</td>\n",
       "      <td>[C, Makefile, Shell, Roff, Perl, M4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bogdanp / awesome-advent-of-code</td>\n",
       "      <td>NA</td>\n",
       "      <td>957</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>palera1n / palera1n</td>\n",
       "      <td>NA</td>\n",
       "      <td>23</td>\n",
       "      <td>[Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t3-oss / create-t3-app</td>\n",
       "      <td>NA</td>\n",
       "      <td>134</td>\n",
       "      <td>[TypeScript, Astro, CSS, JavaScript, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>maplecool / easytrojan</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>[Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>openai / openai-quickstart-node</td>\n",
       "      <td>NA</td>\n",
       "      <td>3</td>\n",
       "      <td>[JavaScript, CSS, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>microsoft / PowerToys</td>\n",
       "      <td>NA</td>\n",
       "      <td>323</td>\n",
       "      <td>[C#, C++, C, PowerShell, HTML, HLSL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>evrone / go-clean-template</td>\n",
       "      <td>NA</td>\n",
       "      <td>9</td>\n",
       "      <td>[Go, Makefile, Dockerfile, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>openzfs / zfs</td>\n",
       "      <td>NA</td>\n",
       "      <td>524</td>\n",
       "      <td>[C, Shell, Assembly, M4, Python, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>recloudstream / cloudstream</td>\n",
       "      <td>NA</td>\n",
       "      <td>69</td>\n",
       "      <td>[Kotlin, Java]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fspoettel / advent-of-code-rust</td>\n",
       "      <td>NA</td>\n",
       "      <td>4</td>\n",
       "      <td>[Rust, RenderScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>getify / You-Dont-Know-JS</td>\n",
       "      <td>NA</td>\n",
       "      <td>180</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>openai / openai-quickstart-python</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>[CSS, Python, HTML, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>linebender / xilem</td>\n",
       "      <td>NA</td>\n",
       "      <td>7</td>\n",
       "      <td>[Rust]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title Description Contributors_count  \\\n",
       "0                   invoke-ai / InvokeAI          NA                130   \n",
       "1            apple / ml-stable-diffusion          NA                  2   \n",
       "2                       AleoHQ / snarkOS          NA                 45   \n",
       "3                  misskey-dev / misskey          NA                121   \n",
       "4                    Klipper3d / klipper          NA                327   \n",
       "5        PKUFlyingPig / cs-self-learning          NA                 70   \n",
       "6             danielgross / whatsapp-gpt          NA                  2   \n",
       "7     hehonghui / awesome-english-ebooks          NA                 NA   \n",
       "8   Visualize-ML / Book4_Power-of-Matrix          NA                 NA   \n",
       "9             thangchung / go-coffeeshop          NA                 NA   \n",
       "10                     monicahq / monica          NA                251   \n",
       "11                   coolsnowwolf / lede          NA                355   \n",
       "12      Bogdanp / awesome-advent-of-code          NA                957   \n",
       "13                   palera1n / palera1n          NA                 23   \n",
       "14                t3-oss / create-t3-app          NA                134   \n",
       "15                maplecool / easytrojan          NA                 NA   \n",
       "16       openai / openai-quickstart-node          NA                  3   \n",
       "17                 microsoft / PowerToys          NA                323   \n",
       "18            evrone / go-clean-template          NA                  9   \n",
       "19                         openzfs / zfs          NA                524   \n",
       "20           recloudstream / cloudstream          NA                 69   \n",
       "21       fspoettel / advent-of-code-rust          NA                  4   \n",
       "22             getify / You-Dont-Know-JS          NA                180   \n",
       "23     openai / openai-quickstart-python          NA                 NA   \n",
       "24                    linebender / xilem          NA                  7   \n",
       "\n",
       "                                        Language_used  \n",
       "0   [Jupyter Notebook, Python, TypeScript, SCSS, S...  \n",
       "1                                     [Python, Swift]  \n",
       "2                                       [Rust, Shell]  \n",
       "3       [TypeScript, Vue, JavaScript, Pug, SCSS, CSS]  \n",
       "4         [C, Python, C++, Assembly, Makefile, Shell]  \n",
       "5                                              [HTML]  \n",
       "6                                        [Go, Python]  \n",
       "7                                               [CSS]  \n",
       "8                                            [Python]  \n",
       "9   [Go, HTML, HCL, JavaScript, CSS, Shell, Makefile]  \n",
       "10     [PHP, Vue, Blade, Shell, Dockerfile, Makefile]  \n",
       "11               [C, Makefile, Shell, Roff, Perl, M4]  \n",
       "12                                               [NA]  \n",
       "13                                            [Shell]  \n",
       "14        [TypeScript, Astro, CSS, JavaScript, Shell]  \n",
       "15                                            [Shell]  \n",
       "16                           [JavaScript, CSS, Shell]  \n",
       "17               [C#, C++, C, PowerShell, HTML, HLSL]  \n",
       "18                  [Go, Makefile, Dockerfile, Shell]  \n",
       "19         [C, Shell, Assembly, M4, Python, Makefile]  \n",
       "20                                     [Kotlin, Java]  \n",
       "21                               [Rust, RenderScript]  \n",
       "22                                               [NA]  \n",
       "23                         [CSS, Python, HTML, Shell]  \n",
       "24                                             [Rust]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github=pd.DataFrame({'Title':Title,'Description':Description,\n",
    "                'Contributors_count':Count,'Language_used':Language})\n",
    "print('\\033[1m'+'GitHub Trending Repository :'+'\\033[0m')\n",
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee49c6",
   "metadata": {},
   "source": [
    "**6. Scrape the details of top 100 songs on billiboard.com.**\n",
    "\n",
    "Url = https:/www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "845c6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage https:/www.billboard.com/\n",
    "\n",
    "url_6 = 'https:/www.billboard.com/'\n",
    "\n",
    "driver.get(url_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e992ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on Chart option\n",
    "charts=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[1]/div/div/div[1]/div[4]/div/nav/ul/li[1]/a')\n",
    "try:\n",
    "    charts.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(charts.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c3caf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on View Chart option\n",
    "view=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a')\n",
    "try:\n",
    "    view.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(view.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab6919c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Song =[]\n",
    "Artist =[]\n",
    "Last_Week_rank=[]\n",
    "Peak_rank =[]\n",
    "Weeks =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b78188fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "song = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]')\n",
    "for i in song:\n",
    "    Song.append(i.text.split('\\n')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26bab172",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]')\n",
    "for i in artist:\n",
    "    Artist.append(i.text.split('\\n')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8eaf90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lwk = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]')\n",
    "for i in lwk:\n",
    "    Last_Week_rank.append(i.text.split('\\n')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2889ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]')\n",
    "for i in peak:\n",
    "    Peak_rank.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d96ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "week = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]')\n",
    "for i in week:\n",
    "    Weeks.append(i.text.split('\\n')[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a88d673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBillboard Hot 100 Songs :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rich Flex</td>\n",
       "      <td>Drake &amp; 21 Savage</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad Habit</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Die For You</td>\n",
       "      <td>Joji</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RE- ENTRY</td>\n",
       "      <td>Down Home</td>\n",
       "      <td>Jimmie Allen</td>\n",
       "      <td>-</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Going, Going, Gone</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Middle Of The Ocean</td>\n",
       "      <td>Drake</td>\n",
       "      <td>67</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>More M’s</td>\n",
       "      <td>Drake &amp; 21 Savage</td>\n",
       "      <td>69</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Song_Name             Artist_Name Last_week_rank  \\\n",
       "0                         Anti-Hero            Taylor Swift              1   \n",
       "1                         Rich Flex       Drake & 21 Savage              2   \n",
       "2                            Unholy  Sam Smith & Kim Petras              3   \n",
       "3                         Bad Habit              Steve Lacy              4   \n",
       "4   All I Want For Christmas Is You            Mariah Carey             25   \n",
       "..                              ...                     ...            ...   \n",
       "95                      Die For You                    Joji             72   \n",
       "96                        RE- ENTRY               Down Home   Jimmie Allen   \n",
       "97               Going, Going, Gone              Luke Combs             99   \n",
       "98              Middle Of The Ocean                   Drake             67   \n",
       "99                         More M’s       Drake & 21 Savage             69   \n",
       "\n",
       "   Peak Weeks_on_chart  \n",
       "0     1              5  \n",
       "1     2              3  \n",
       "2     1              9  \n",
       "3     1             21  \n",
       "4     1             53  \n",
       "..  ...            ...  \n",
       "95   53              3  \n",
       "96    -             88  \n",
       "97   98              2  \n",
       "98   15              3  \n",
       "99   18              3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Billboard=pd.DataFrame({'Song_Name':Song,\n",
    "                'Artist_Name':Artist,\n",
    "                'Last_week_rank':Last_Week_rank,\n",
    "                'Peak':Peak_rank,\n",
    "                'Weeks_on_chart':Weeks})\n",
    "print('\\033[1m'+'Billboard Hot 100 Songs :'+'\\033[0m')\n",
    "Billboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08199af1",
   "metadata": {},
   "source": [
    "**7. Scrape the details of Data science recruiters from naukri.com.**\n",
    "\n",
    "Url = https://www.naukri.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28810479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage https://www.naukri.com/\n",
    "\n",
    "url_7 = 'https://www.naukri.com/'\n",
    "\n",
    "driver.get(url_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f121cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on search option\n",
    "\n",
    "button = driver.find_element(By.XPATH,'//*[@id=\"root\"]/div[6]/div/div/div[6]')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f005d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Name =[]\n",
    "Designation =[]\n",
    "Company =[]\n",
    "Skill =[]\n",
    "Location =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "efba88db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping  Name\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        Name.append('NA')\n",
    "\n",
    "    # Scraping Designation\n",
    "try:\n",
    "    designation=driver.find_elements(By.XPATH,'//p[@class=\"highlightable\"]/span[1]')\n",
    "    for i in designation:\n",
    "        Designation.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Designation.append('NA')\n",
    "    \n",
    "# Scraping Company\n",
    "try:\n",
    "    company=driver.find_elements(By.XPATH,'//a[@class=\"ellipsis\"][2]')\n",
    "    for i in company:\n",
    "        Company.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Company.append('NA')\n",
    "# Scraping skill for they hire\n",
    "try:\n",
    "    skill=driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')\n",
    "    for i in skill:\n",
    "        Skill.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Skill.append('NA')\n",
    "    \n",
    "# Scraping Song Artist Name\n",
    "try:\n",
    "    location=driver.find_elements(By.XPATH,'//p[@class=\"highlightable\"]/span[2]/small')\n",
    "    if location:\n",
    "        for i in location:\n",
    "            Location.append(i.text)\n",
    "    else:\n",
    "        Location.append('NA')\n",
    "except NoSuchElementException:\n",
    "    Location.append('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27183c",
   "metadata": {},
   "source": [
    "**8. Scrape the details of Highest selling novels.**\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a717ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "\n",
    "url_8 = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "\n",
    "driver.get(url_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c2c17049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty Lists\n",
    "Book =[]\n",
    "Author =[]\n",
    "Volumes_sold =[]\n",
    "Publisher =[]\n",
    "Genre =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c34fcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book name\n",
    "try:\n",
    "    book=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book:\n",
    "        Book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book.append('NA')\n",
    "    \n",
    "# Scraping Book author's via Xpath\n",
    "try:\n",
    "    author=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author:\n",
    "        Author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author.append('NA')\n",
    "    \n",
    "# Scraping Volumes sold via Xpath\n",
    "try:\n",
    "    sold=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in sold:\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volumes_sold.append('NA')\n",
    "    \n",
    "# Scraping publisher via xPath\n",
    "try:\n",
    "    publisher=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "69d0511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest Selling Books of All Time List by The Guardian  :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Title       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "Top_Books=pd.DataFrame({\"Book Title\":Book,\n",
    "                \"Author Name\":Author,\n",
    "                'Volumes sold':Volumes_sold,\n",
    "                'Publisher':Publisher,\n",
    "                'Genre':Genre})\n",
    "print('\\033[1m'+'Best Selling Books of All Time List by The Guardian  :'+'\\033[0m')\n",
    "Top_Books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c561d6",
   "metadata": {},
   "source": [
    "**9. Scrape the details most watched tv series of all time from imdb.com.**\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b106020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "url_9 = 'https://www.imdb.com/list/ls095964455/'\n",
    "\n",
    "driver.get(url_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "35c00717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Name =[]\n",
    "Year_Span=[]\n",
    "Genre =[]\n",
    "Run_Time =[]\n",
    "Ratings =[]\n",
    "Votes =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1753027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name via Xpath\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')\n",
    "\n",
    "# Scraping Year span via Xpath\n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in year:\n",
    "        Year_Span.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year_Span.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')\n",
    "    \n",
    "# Scraping RunTime via Xpath\n",
    "try:\n",
    "    runtime=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in runtime:\n",
    "        Run_Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Run_Time.append('NA')\n",
    "\n",
    "# Scraping Ratings via Xpath\n",
    "try:\n",
    "    ratings=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    for i in ratings:\n",
    "        Ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Ratings.append('NA')\n",
    "\n",
    "# Scraping Votes via Xpath\n",
    "try:\n",
    "    votes=driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Votes.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "281b1404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 100 most watched tv shows of all time IMDB :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,089,382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,178,987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>988,537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>292,785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>251,925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>198,223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>245,120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,089,382  \n",
       "1    51 min     8.7  1,178,987  \n",
       "2    44 min     8.1    988,537  \n",
       "3    60 min     7.5    292,785  \n",
       "4    43 min     7.6    251,925  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,168  \n",
       "96   50 min     7.8     61,432  \n",
       "97   42 min     8.1    198,223  \n",
       "98   45 min     7.1     41,570  \n",
       "99  572 min     8.6    245,120  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "IMDB_TV=pd.DataFrame({\"Name\":Name,\n",
    "                \"Year Span\":Year_Span,\n",
    "                \"Genre\":Genre,\n",
    "                \"Run Time\":Run_Time,\n",
    "                \"Ratings\":Ratings,\n",
    "                \"Votes\":Votes})\n",
    "print('\\033[1m'+'Top 100 most watched tv shows of all time IMDB :'+'\\033[0m')\n",
    "IMDB_TV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafd09c",
   "metadata": {},
   "source": [
    "**10. Details of Datasets from UCI machine learning repositories.**\n",
    "\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e3b6ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to the web driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Admin\\Chrome webdriver\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Let's maximize the automated window\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "# First get the webpage https://archive.ics.uci.edu/\n",
    "\n",
    "url_10 = 'https://archive.ics.uci.edu/'\n",
    "\n",
    "driver.get(url_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cc65e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on all datasets links\n",
    "dataset=driver.find_element(By.XPATH,\"//a[@href='datasets.php']\")\n",
    "dataset.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d08e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Dataset =[]\n",
    "Data_Type =[]\n",
    "Task =[]\n",
    "Attribute_Type =[]\n",
    "No_of_Instances =[]\n",
    "No_of_Attribute =[]\n",
    "Year =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b54fcdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 622/622 [01:56<00:00,  5.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Scraping DataSet Name via Xpath\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    dataset=driver.find_elements(By.XPATH,\"//p[@class='normal']/b/a\")\n",
    "    for i in tqdm(dataset):\n",
    "        Dataset.append(i.text)\n",
    "        time.sleep(0.15)\n",
    "except NoSuchElementException:\n",
    "    Dataset.append('NA')\n",
    "    \n",
    "# Scraping Data Type via Xpath\n",
    "try:\n",
    "    Type=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "    for i in Type[1:]:\n",
    "        Data_Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Data_Type.append('NA')\n",
    "    \n",
    "# Scraping Task via Xpath\n",
    "try:\n",
    "    task=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "    for i in task[1:]:\n",
    "        Task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append('NA')\n",
    "    \n",
    "# Scraping Attribute_Type via Xpath\n",
    "try:\n",
    "    attribute_Type=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "    for i in attribute_Type[1:]:\n",
    "        Attribute_Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Attribute_Type.append('NA')\n",
    "    \n",
    "# Scraping No_of_Instances via Xpath\n",
    "try:\n",
    "    no_of_Instances=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "    for i in no_of_Instances[1:]:\n",
    "        No_of_Instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Instances.append('NA')\n",
    "\n",
    "# Scraping No_of_Attribute via Xpath\n",
    "try:\n",
    "    no_of_Attribute=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "    for i in no_of_Attribute[1:]:\n",
    "        No_of_Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Attribute.append('NA')\n",
    "    \n",
    "# Scraping Year via Xpath\n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "    for i in year[1:]:\n",
    "        Year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3fb2b4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 622, 622, 622, 622, 622)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset),len(Data_Type),len(Task),len(Attribute_Type),len(No_of_Instances),len(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a82d6ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m UCI Machine Learning Dataset:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet Title</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DataSet Title  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data Type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute Type No of Instances No of Attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame for UCI Dataset\n",
    "UCI_Dataset=pd.DataFrame({'DataSet Title':Dataset,\n",
    "                'Data Type':Data_Type,\n",
    "                'Task':Task,\n",
    "                'Attribute Type':Attribute_Type,\n",
    "                'No of Instances':No_of_Instances,\n",
    "                'No of Attribute':No_of_Attribute,\n",
    "                'Year':Year})\n",
    "print('\\033[1m'+' UCI Machine Learning Dataset:'+'\\033[0m')\n",
    "UCI_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b9a58dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6e0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
